{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARD IMPORTS\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# analysis\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# data handling\n",
    "!pip3 install ../../../h5flow\n",
    "import h5flow\n",
    "from h5flow.data import dereference\n",
    "\n",
    "## 3D PLOTTING\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import BoundaryNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'mc_processed_MiniRun5_1E19_RHC.flow.0000000.FLOW_nfiles_6_TrapType_evts_all'\n",
    "\n",
    "# print configuration and hit configuration\n",
    "config_filename = dirname+'/config.json'\n",
    "with open(config_filename) as json_file:\n",
    "    config = json.load(json_file)\n",
    "    print(json.dumps(config, indent=4))\n",
    "\n",
    "\n",
    "# loop over nfiles from config.json\n",
    "nfiles = config['nfiles']\n",
    "\n",
    "spes_filenames = []\n",
    "noise_filenames = []\n",
    "hits_filenames = []\n",
    "hits_config_filenames = []\n",
    "true_hits_filenames = []\n",
    "\n",
    "for i in range(nfiles):\n",
    "    spes_filenames.append(dirname + f'/spes_evt_{i}.npz')\n",
    "    noise_filenames.append(dirname + f'/noise_evt_{i}.npz')\n",
    "    hits_filenames.append(dirname + f'/hits_evt_{i}.npz')\n",
    "    hits_config_filenames.append(dirname + f'/hits_config_{i}.json')\n",
    "    true_hits_filenames.append(dirname + f'/true_hits_{i}.csv')\n",
    "\n",
    "    with open(hits_config_filenames[i]) as json_file:\n",
    "        hits_config = json.load(json_file)\n",
    "        print(f'Config for file {i}:')\n",
    "        print(json.dumps(hits_config, indent=4))\n",
    "\n",
    "    # check if true hits file exists\n",
    "    if os.path.exists(true_hits_filenames[i]):\n",
    "        true_hits = pd.read_csv(true_hits_filenames[i])\n",
    "        print(f'True hits for file {i}:')\n",
    "        print(true_hits.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def clopper_pearson_interval(k, n, alpha=0.6827):\n",
    "    alpha = 1 - alpha\n",
    "    lo = scipy.stats.beta.ppf(alpha / 2, k, n - k + 1) if k > 0 else 0.0\n",
    "    hi = scipy.stats.beta.ppf(1 - alpha / 2, k + 1, n - k) if k < n else 1.0\n",
    "    return lo, hi\n",
    "\n",
    "\n",
    "# gaussian fit func\n",
    "def gaussian(x, A, mu, sig):\n",
    "    return A * np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 6\n",
    "\n",
    "# info by trap type (ArClight)\n",
    "acl_rec_true_hits_tot = 0\n",
    "acl_true_hits_tot = 0\n",
    "acl_rec_hits_tot = 0\n",
    "acl_delta_t = []\n",
    "# info by trap type (LCM)\n",
    "lcm_rec_true_hits_tot = 0\n",
    "lcm_true_hits_tot = 0\n",
    "lcm_rec_hits_tot = 0\n",
    "lcm_delta_t = []\n",
    "\n",
    "# info by trap type (ArClight) binned by pileup\n",
    "acl_rec_true_hits_pu = []\n",
    "acl_true_hits_pu = []\n",
    "acl_rec_hits_pu = []\n",
    "acl_delta_t_pu = []\n",
    "# info by trap type (LCM) binned by pileup\n",
    "lcm_rec_true_hits_pu = []\n",
    "lcm_true_hits_pu = []\n",
    "lcm_rec_hits_pu = []\n",
    "lcm_delta_t_pu = []\n",
    "\n",
    "# loop over files\n",
    "for i_file in range(nfiles):\n",
    "\n",
    "    print(f'File {i_file}:')\n",
    "    #print(spes_filenames[i_file])\n",
    "    #print(noise_filenames[i_file])\n",
    "    #print(hits_filenames[i_file])\n",
    "    #print(true_hits_filenames[i_file])\n",
    "\n",
    "    acl_rec_true_hits = 0\n",
    "    acl_true_hits = 0\n",
    "    acl_rec_hits = 0\n",
    "\n",
    "    lcm_rec_true_hits = 0\n",
    "    lcm_true_hits = 0\n",
    "    lcm_rec_hits = 0\n",
    "\n",
    "    # load true hits\n",
    "    true_hits = pd.read_csv(true_hits_filenames[i_file])\n",
    "    true_hit_idxs = true_hits['start_time_idx'].values\n",
    "\n",
    "    # load ticks histogram of all hits\n",
    "    hits_file = np.load(hits_filenames[i_file])\n",
    "    hits_arr = hits_file['arr_0']\n",
    "    flat_hits = np.sum(hits_arr, axis=(0,1))\n",
    "\n",
    "    # loop over events\n",
    "    for i_evt_lrs in range(hits_arr.shape[0]):\n",
    "\n",
    "        # loop over traps\n",
    "        for i_trap in range(hits_arr.shape[1]):\n",
    "            is_acl = i_trap % 2 == 0\n",
    "            i_tpc = i_trap // 2\n",
    "\n",
    "            hits = np.where(hits_arr[i_evt_lrs, i_trap])[0]\n",
    "            true_hit_idxs_tpc = true_hits[(true_hits['event_id'] == i_evt_lrs) & (true_hits['tpc_num'] == i_tpc)]['start_time_idx'].values\n",
    "\n",
    "            # ACLs\n",
    "            if is_acl:\n",
    "\n",
    "                # add true hits\n",
    "                acl_true_hits += len(true_hit_idxs_tpc)\n",
    "                # fill pileup histogram with length-of-true-hits length-of-true-hits times\n",
    "                for i in range(len(true_hit_idxs_tpc)):\n",
    "                    acl_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "                # add rec hits\n",
    "                for i_hit in hits:\n",
    "                    acl_rec_hits += 1\n",
    "                    acl_rec_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "                    # check if true hit is within tolerance in this specific tpc\n",
    "\n",
    "                    # get true hit indices within tolerance of this hit\n",
    "                    delta_ts = (i_hit - true_hit_idxs_tpc)\n",
    "                    delta_ts = delta_ts[(delta_ts < tolerance) & (delta_ts > 0)]\n",
    "                    if delta_ts.size > 0:\n",
    "                        delta_ts = min(delta_ts)\n",
    "                        acl_delta_t.append(delta_ts)\n",
    "\n",
    "                        # add to true rec hits\n",
    "                        acl_rec_true_hits += 1\n",
    "                        acl_rec_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "            else:\n",
    "\n",
    "                # add true hits\n",
    "                lcm_true_hits += len(true_hit_idxs_tpc)\n",
    "                # fill pileup histogram with length-of-true-hits length-of-true-hits times\n",
    "                for i in range(len(true_hit_idxs_tpc)):\n",
    "                    lcm_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "                # add rec hits\n",
    "                for i_hit in hits:\n",
    "                    lcm_rec_hits += 1\n",
    "                    lcm_rec_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "                    # get true hit indices within tolerance of this hit\n",
    "                    delta_ts = (i_hit - true_hit_idxs_tpc)\n",
    "                    delta_ts = delta_ts[(delta_ts < tolerance) & (delta_ts > 0)]\n",
    "                    if delta_ts.size > 0:\n",
    "                        delta_ts = min(delta_ts)\n",
    "                        lcm_delta_t.append(delta_ts)\n",
    "\n",
    "                        # add to true rec hits\n",
    "                        lcm_rec_true_hits += 1\n",
    "                        lcm_rec_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "    # caluclate efficiency +/- clopper pearson\n",
    "    '''\n",
    "    print(f'ACL True Hits: {acl_true_hits}')\n",
    "    print(f'ACL Rec Hits: {acl_rec_hits}')\n",
    "    print(f'ACL Rec True Hits: {acl_rec_true_hits}')\n",
    "\n",
    "    print(f'LCM True Hits: {lcm_true_hits}')\n",
    "    print(f'LCM Rec Hits: {lcm_rec_hits}')\n",
    "    print(f'LCM Rec True Hits: {lcm_rec_true_hits}')\n",
    "    '''\n",
    "\n",
    "    # ACL efficiency\n",
    "    acl_eff = acl_rec_true_hits / acl_true_hits\n",
    "    acl_eff_err = clopper_pearson_interval(acl_rec_true_hits, acl_true_hits)\n",
    "    #print(f'ACL Efficiency: {acl_eff:.2f} + {acl_eff_err[1] - acl_eff:.2f} - {acl_eff - acl_eff_err[0]:.2f}')\n",
    "    # ACL fake rate\n",
    "    acl_fake_rate = 1 - (acl_rec_true_hits / acl_rec_hits)\n",
    "    acl_fake_rate_err = clopper_pearson_interval(acl_rec_true_hits, acl_rec_hits)\n",
    "    #print(f'ACL Fake Rate: {acl_fake_rate:.2f} + {1 - acl_fake_rate_err[0] - acl_fake_rate:.2f} - {1 - acl_fake_rate_err[1] - acl_fake_rate:.2f}')\n",
    "\n",
    "    # LCM efficiency\n",
    "    lcm_eff = lcm_rec_true_hits / lcm_true_hits\n",
    "    lcm_eff_err = clopper_pearson_interval(lcm_rec_true_hits, lcm_true_hits)\n",
    "    #print(f'LCM Efficiency: {lcm_eff:.2f} + {lcm_eff_err[1] - lcm_eff:.2f} - {lcm_eff - lcm_eff_err[0]:.2f}')\n",
    "\n",
    "    # LCM fake rate\n",
    "    lcm_fake_rate = 1 - (lcm_rec_true_hits / lcm_rec_hits)\n",
    "    lcm_fake_rate_err = clopper_pearson_interval(lcm_rec_true_hits, lcm_rec_hits)\n",
    "    #print(f'LCM Fake Rate: {lcm_fake_rate:.2f} + {1 - lcm_fake_rate_err[0] - lcm_fake_rate:.2f} - {1 - lcm_fake_rate_err[1] - lcm_fake_rate:.2f}')\n",
    "\n",
    "    # add to totals\n",
    "    acl_rec_true_hits_tot += acl_rec_true_hits\n",
    "    acl_true_hits_tot += acl_true_hits\n",
    "    acl_rec_hits_tot += acl_rec_hits\n",
    "\n",
    "    lcm_rec_true_hits_tot += lcm_rec_true_hits\n",
    "    lcm_true_hits_tot += lcm_true_hits\n",
    "    lcm_rec_hits_tot += lcm_rec_hits\n",
    "\n",
    "\n",
    "# caluclate efficiency +/- clopper pearson\n",
    "print('All files: ')\n",
    "print(f'ACL True Hits: {acl_true_hits_tot}')\n",
    "print(f'ACL Rec Hits: {acl_rec_hits_tot}')\n",
    "print(f'ACL Rec True Hits: {acl_rec_true_hits_tot}')\n",
    "\n",
    "print(f'LCM True Hits: {lcm_true_hits_tot}')\n",
    "print(f'LCM Rec Hits: {lcm_rec_hits_tot}')\n",
    "print(f'LCM Rec True Hits: {lcm_rec_true_hits_tot}')\n",
    "\n",
    "# ACL efficiency\n",
    "acl_eff = acl_rec_true_hits_tot / acl_true_hits_tot\n",
    "acl_eff_err = clopper_pearson_interval(acl_rec_true_hits_tot, acl_true_hits_tot)\n",
    "print(f'ACL Efficiency: {acl_eff:.2f} + {acl_eff_err[1] - acl_eff:.2f} - {acl_eff - acl_eff_err[0]:.2f}')\n",
    "# ACL fake rate\n",
    "acl_fake_rate = 1 - (acl_rec_true_hits_tot / acl_rec_hits_tot)\n",
    "acl_fake_rate_err = clopper_pearson_interval(acl_rec_true_hits, acl_rec_hits)\n",
    "print(f'ACL Fake Rate: {acl_fake_rate:.2f} + {1 - acl_fake_rate_err[0] - acl_fake_rate:.2f} - {1 - acl_fake_rate_err[1] - acl_fake_rate:.2f}')\n",
    "\n",
    "# LCM efficiency\n",
    "lcm_eff = lcm_rec_true_hits_tot / lcm_true_hits_tot\n",
    "lcm_eff_err = clopper_pearson_interval(lcm_rec_true_hits_tot, lcm_true_hits_tot)\n",
    "print(f'LCM Efficiency: {lcm_eff:.2f} + {lcm_eff_err[1] - lcm_eff:.2f} - {lcm_eff - lcm_eff_err[0]:.2f}')\n",
    "\n",
    "# LCM fake rate\n",
    "lcm_fake_rate = 1 - (lcm_rec_true_hits_tot / lcm_rec_hits_tot)\n",
    "lcm_fake_rate_err = clopper_pearson_interval(lcm_rec_true_hits_tot, lcm_rec_hits_tot)\n",
    "print(f'LCM Fake Rate: {lcm_fake_rate:.2f} + {1 - lcm_fake_rate_err[0] - lcm_fake_rate:.2f} - {1 - lcm_fake_rate_err[1] - lcm_fake_rate:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_sided_crystal_ball(x, beta1, m1, beta2, m2, loc, scale, amplitude):\n",
    "    \"\"\"\n",
    "    A smooth Double-Sided Crystal Ball function.\n",
    "\n",
    "    Parameters:\n",
    "    - x: Data points.\n",
    "    - beta1, m1: Left tail parameters (beta1 = tail exponent, m1 = curvature).\n",
    "    - beta2, m2: Right tail parameters.\n",
    "    - loc: Center of the distribution (mean).\n",
    "    - scale: Core width (sigma).\n",
    "    - amplitude: Scaling factor.\n",
    "\n",
    "    Returns:\n",
    "    - Smooth DSCB function values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalized distance from mean\n",
    "    t = (x - loc) / scale\n",
    "\n",
    "    # Transition points\n",
    "    left_cutoff = -beta1\n",
    "    right_cutoff = beta2\n",
    "\n",
    "    y = np.zeros_like(t)\n",
    "\n",
    "    # Left tail (x < loc - beta1 * scale)\n",
    "    left_mask = t < left_cutoff\n",
    "    if np.any(left_mask):\n",
    "        A1 = (m1 / beta1) ** m1 * np.exp(-0.5 * beta1 ** 2)\n",
    "        B1 = m1 / beta1 - beta1\n",
    "        y[left_mask] = A1 * (B1 - t[left_mask]) ** -m1\n",
    "\n",
    "    # Core Gaussian (-beta1 < t < beta2)\n",
    "    core_mask = (t >= left_cutoff) & (t <= right_cutoff)\n",
    "    if np.any(core_mask):\n",
    "        y[core_mask] = np.exp(-0.5 * t[core_mask] ** 2)\n",
    "\n",
    "    # Right tail (x > loc + beta2 * scale)\n",
    "    right_mask = t > right_cutoff\n",
    "    if np.any(right_mask):\n",
    "        A2 = (m2 / beta2) ** m2 * np.exp(-0.5 * beta2 ** 2)\n",
    "        B2 = m2 / beta2 - beta2\n",
    "        y[right_mask] = A2 * (B2 + t[right_mask]) ** -m2\n",
    "\n",
    "    return amplitude * y\n",
    "\n",
    "\n",
    "def plot_histogram_and_fit(ax_main, ax_resid, delta_t, color, label, nbins=10):\n",
    "    # Histogram\n",
    "    ax_main.hist(delta_t, bins=nbins, range=(0, tolerance), histtype='step', color=color, label=label)\n",
    "\n",
    "    # Bin calculations\n",
    "    hist, bin_edges = np.histogram(delta_t, bins=nbins, range=(0, tolerance))\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    sqrtN = np.sqrt(hist)\n",
    "    ax_main.errorbar(bin_centers, hist, yerr=sqrtN, fmt='none', color=color, alpha=0.5)\n",
    "\n",
    "    # Fit Double-sided Crystal Ball\n",
    "    param_bounds = ([0.1, 0.1, 0.1, 0.1, -np.inf, 1e-6, 1e-6], [10, 10, 10, 10, np.inf, np.inf, np.inf])\n",
    "    p0 = [1.5, 2.0, 1.5, 2.0, np.mean(delta_t), np.std(delta_t), max(hist)]\n",
    "    popt, _ = curve_fit(double_sided_crystal_ball, bin_centers, hist, p0=p0, bounds=param_bounds, maxfev=10000)\n",
    "\n",
    "    # Plot fit\n",
    "    ax_main.plot(interp_bin_centres, double_sided_crystal_ball(interp_bin_centres, *popt), color='k', linestyle='--', label=f'{label} fit')\n",
    "\n",
    "    # Labels\n",
    "    ax_main.set_ylabel('Counts')\n",
    "    ax_main.legend()\n",
    "\n",
    "    # Residuals\n",
    "    resids = (hist - double_sided_crystal_ball(bin_centers, *popt))\n",
    "    ax_resid.step(bin_centers, resids/sqrtN, color=color)\n",
    "    ax_resid.fill_between(bin_centers, (resids-sqrtN)/sqrtN, (resids+sqrtN)/sqrtN, color=color, alpha=0.5, step='pre')\n",
    "    ax_resid.axhline(0, color='k', linestyle='--')\n",
    "    ax_resid.set_xlabel('Delta T (ticks)')\n",
    "    ax_resid.set_ylabel(r'($\\sigma$)')\n",
    "\n",
    "    # Print fit parameters on the plot\n",
    "    ax_main.text(0.5, 0.9, f'Beta1: {popt[0]:.2f}', transform=ax_main.transAxes)\n",
    "    ax_main.text(\n",
    "        0.5, 0.85, f'M1: {popt[1]:.2f}', transform=ax_main.transAxes)\n",
    "    ax_main.text(\n",
    "        0.5, 0.80, f'Beta2: {popt[2]:.2f}', transform=ax_main.transAxes)\n",
    "    ax_main.text(\n",
    "        0.5, 0.75, f'M2: {popt[3]:.2f}', transform=ax_main.transAxes)\n",
    "    ax_main.text(\n",
    "        0.5, 0.70, f'Mean (ns): {popt[4]*16:.2f}', transform=ax_main.transAxes)\n",
    "    ax_main.text(\n",
    "        0.5, 0.65, f'Sigma (ns): {popt[5]*16:.2f}', transform=ax_main.transAxes)\n",
    "    # sigma from fwhm\n",
    "    max_val = np.max(double_sided_crystal_ball(interp_bin_centres, *popt))\n",
    "    fwhm = interp_bin_centres[np.where(double_sided_crystal_ball(interp_bin_centres, *popt) > max_val/2)]\n",
    "    fwhm = fwhm[-1] - fwhm[0]\n",
    "    ax_main.text(0.5, 0.60, f'Sigma_fwhm (ns): {0.425*fwhm*16:.2f}', transform=ax_main.transAxes)\n",
    "\n",
    "# Set up figure with GridSpec\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 5), gridspec_kw={'height_ratios': [3, 1]})\n",
    "interp_bin_centres = np.linspace(0, tolerance, 1000)\n",
    "\n",
    "# Plot ACL\n",
    "plot_histogram_and_fit(ax[0, 0], ax[1, 0], acl_delta_t, 'b', 'ACL')\n",
    "\n",
    "# Plot LCM\n",
    "plot_histogram_and_fit(ax[0, 1], ax[1, 1], lcm_delta_t, 'r', 'LCM')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorised version of clopper_pearson_interval\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def clopper_pearson_interval_numpy(k, n, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Vectorized Clopper-Pearson confidence interval for binomial proportions.\n",
    "\n",
    "    Parameters:\n",
    "    k : array-like\n",
    "        Number of successes (can be an array).\n",
    "    n : array-like\n",
    "        Number of trials (can be an array).\n",
    "    alpha : float, optional\n",
    "        Significance level, default is 0.05 for a 95% confidence interval.\n",
    "\n",
    "    Returns:\n",
    "    ci_lower : ndarray\n",
    "        Lower bound of the confidence interval.\n",
    "    ci_upper : ndarray\n",
    "        Upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    k = np.asarray(k, dtype=np.int64)\n",
    "    n = np.asarray(n, dtype=np.int64)\n",
    "\n",
    "    # Ensure valid values\n",
    "    if np.any(k > n):\n",
    "        raise ValueError(\"Number of successes k cannot be greater than number of trials n\")\n",
    "\n",
    "    alpha_2 = alpha / 2\n",
    "\n",
    "    # Compute lower bound\n",
    "    ci_lower = np.where(\n",
    "        k > 0,\n",
    "        st.beta.ppf(alpha_2, k, n - k + 1),\n",
    "        0.0  # If k == 0, lower bound is 0\n",
    "    )\n",
    "    #ci_lower -= k/n\n",
    "\n",
    "    # Compute upper bound\n",
    "    ci_upper = np.where(\n",
    "        k < n,\n",
    "        st.beta.ppf(1 - alpha_2, k + 1, n - k),\n",
    "        1.0  # If k == n, upper bound is 1\n",
    "    )\n",
    "    #ci_upper -= k/n\n",
    "\n",
    "    return ci_lower, ci_upper\n",
    "\n",
    "\n",
    "# calculate efficiency and fake rate as a function of pileup\n",
    "pu_bins = np.linspace(-1, 7, 9)\n",
    "dt_bins = np.linspace(0, tolerance, tolerance+1)\n",
    "# acl\n",
    "acl_delta_t_puhist = np.histogram2d(acl_rec_true_hits_pu, acl_delta_t, bins=[pu_bins, dt_bins])[0]\n",
    "acl_rec_true_hits_puhist = np.histogram(acl_rec_true_hits_pu, bins=pu_bins)[0]\n",
    "acl_true_hits_puhist = np.histogram(acl_true_hits_pu, bins=pu_bins)[0]\n",
    "acl_rec_hits_puhist = np.histogram(acl_rec_hits_pu, bins=pu_bins)[0]\n",
    "# lcm\n",
    "lcm_delta_t_puhist = np.histogram2d(lcm_rec_true_hits_pu, lcm_delta_t, bins=[pu_bins, dt_bins])[0]\n",
    "lcm_rec_true_hits_puhist = np.histogram(lcm_rec_true_hits_pu, bins=pu_bins)[0]\n",
    "lcm_true_hits_puhist = np.histogram(lcm_true_hits_pu, bins=pu_bins)[0]\n",
    "lcm_rec_hits_puhist = np.histogram(lcm_rec_hits_pu, bins=pu_bins)[0]\n",
    "\n",
    "# acl efficiency in bins of pu\n",
    "acl_eff_pu = acl_rec_true_hits_puhist / acl_true_hits_puhist\n",
    "acl_eff_pu_err = clopper_pearson_interval_numpy(acl_rec_true_hits_puhist, acl_true_hits_puhist)\n",
    "\n",
    "# acl fake rate in bins of pu\n",
    "acl_fake_rate_pu = 1 - (acl_rec_true_hits_puhist / acl_rec_hits_puhist)\n",
    "acl_fake_rate_pu_err = clopper_pearson_interval_numpy(acl_rec_true_hits_puhist, acl_rec_hits_puhist)\n",
    "\n",
    "# lcm efficiency in bins of pu\n",
    "lcm_eff_pu = lcm_rec_true_hits_puhist / lcm_true_hits_puhist\n",
    "lcm_eff_pu_err = clopper_pearson_interval_numpy(lcm_rec_true_hits_puhist, lcm_true_hits_puhist)\n",
    "\n",
    "# lcm fake rate in bins of pu\n",
    "lcm_fake_rate_pu = 1 - (lcm_rec_true_hits_puhist / lcm_rec_hits_puhist)\n",
    "lcm_fake_rate_pu_err = clopper_pearson_interval_numpy(lcm_rec_true_hits_puhist, lcm_rec_hits_puhist)\n",
    "\n",
    "# plot efficiency and fake rate as a function of pileup\n",
    "fig, ax = plt.subplots(2, figsize=(8, 5))\n",
    "\n",
    "# plot acl efficiency\n",
    "ax[0].step(pu_bins[:-1], acl_eff_pu, label='ACL')\n",
    "ax[0].fill_between(pu_bins[:-1], acl_eff_pu_err[0], acl_eff_pu_err[1], step='pre', alpha=0.2)\n",
    "# plot lcm efficiency\n",
    "ax[0].step(pu_bins[:-1], lcm_eff_pu, label='LCM')\n",
    "ax[0].fill_between(pu_bins[:-1], lcm_eff_pu_err[0], lcm_eff_pu_err[1], step='pre', alpha=0.2)\n",
    "# formatting\n",
    "ax[0].set_ylabel('Efficiency')\n",
    "ax[0].set_xlabel('Pileup')\n",
    "ax[0].set_xlim(0, 6)\n",
    "ax[0].legend()\n",
    "\n",
    "# plot acl fake rate\n",
    "ax[1].step(pu_bins[:-1], acl_fake_rate_pu, label='ACL')\n",
    "ax[1].fill_between(pu_bins[:-1], 1-acl_fake_rate_pu_err[0], 1-acl_fake_rate_pu_err[1], step='pre', alpha=0.2)\n",
    "# plot lcm fake rate\n",
    "ax[1].step(pu_bins[:-1], lcm_fake_rate_pu, label='LCM')\n",
    "ax[1].fill_between(pu_bins[:-1], 1-lcm_fake_rate_pu_err[0], 1-lcm_fake_rate_pu_err[1], step='pre', alpha=0.2)\n",
    "# formatting\n",
    "ax[1].set_ylabel('Fake Rate')\n",
    "ax[1].set_xlabel('Pileup')\n",
    "ax[1].set_xlim(0, 6)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndlar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
