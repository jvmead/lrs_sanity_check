{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def clopper_pearson_interval(k, n, alpha=0.6827):\n",
    "    alpha = 1 - alpha\n",
    "    lo = scipy.stats.beta.ppf(alpha / 2, k, n - k + 1) if k > 0 else 0.0\n",
    "    hi = scipy.stats.beta.ppf(1 - alpha / 2, k + 1, n - k) if k < n else 1.0\n",
    "    return lo, hi\n",
    "\n",
    "\n",
    "# gaussian fit func\n",
    "def gaussian(x, A, mu, sig):\n",
    "    return A * np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARD IMPORTS\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# analysis\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# data handling\n",
    "!pip3 install ../../../h5flow\n",
    "import h5flow\n",
    "from h5flow.data import dereference\n",
    "\n",
    "## 3D PLOTTING\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import BoundaryNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'mc_processed_MiniRun5_1E19_RHC.flow.0000000.FLOW_nfiles_6_TrapType_evts_all'\n",
    "\n",
    "# print configuration and hit configuration\n",
    "config_filename = dirname+'/config.json'\n",
    "with open(config_filename) as json_file:\n",
    "    config = json.load(json_file)\n",
    "    #print(json.dumps(config, indent=4))\n",
    "\n",
    "\n",
    "# loop over nfiles from config.json\n",
    "nfiles = config['nfiles']\n",
    "\n",
    "spes_filenames = []\n",
    "noise_filenames = []\n",
    "hits_filenames = []\n",
    "peaks_filenames = []\n",
    "hits_config_filenames = []\n",
    "true_hits_filenames = []\n",
    "\n",
    "for i in range(nfiles):\n",
    "    spes_filenames.append(dirname + f'/spes_evt_{i}.npz')\n",
    "    noise_filenames.append(dirname + f'/noise_evt_{i}.npz')\n",
    "    hits_filenames.append(dirname + f'/hits_evt_{i}.npz')\n",
    "    peaks_filenames.append(dirname + f'/peaks_evt_{i}.npz')\n",
    "    hits_config_filenames.append(dirname + f'/hits_config_{i}.json')\n",
    "    true_hits_filenames.append(dirname + f'/true_hits_{i}.csv')\n",
    "\n",
    "    with open(hits_config_filenames[i]) as json_file:\n",
    "        hits_config = json.load(json_file)\n",
    "        #print(f'Config for file {i}:')\n",
    "        #\n",
    "    # check if true hits file exists\n",
    "    if os.path.exists(true_hits_filenames[i]):\n",
    "        true_hits = pd.read_csv(true_hits_filenames[i])\n",
    "        #print(f'True hits for file {i}:')\n",
    "        #print(true_hits.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "# load hit finder config\n",
    "with open(hits_config_filenames[0]) as json_file:\n",
    "    hits_config = json.load(json_file)\n",
    "n_noise_factor = hits_config['n_noise_factor']\n",
    "n_bins_rolled = hits_config['n_bins_rolled']\n",
    "n_sqrt_rt_factor = hits_config['n_sqrt_rt_factor']\n",
    "pe_weight = hits_config['pe_weight']\n",
    "\n",
    "\n",
    "# loading events\n",
    "time_bins = np.linspace(0, 16, 1000)\n",
    "\n",
    "# wvfms\n",
    "summed_wvfms_file = np.load(spes_filenames[0])\n",
    "summed_wvfms = np.array(summed_wvfms_file['arr_0'])\n",
    "\n",
    "# noise thresholds\n",
    "heights_file = np.load(noise_filenames[0])\n",
    "heights = np.array(heights_file['arr_0'])\n",
    "\n",
    "# loading hits\n",
    "hits_file = np.load(hits_filenames[0])\n",
    "hits = np.array(hits_file['arr_0'])\n",
    "\n",
    "# true hits\n",
    "true_hits_file = pd.read_csv(true_hits_filenames[0])\n",
    "# use headers for dataframe\n",
    "true_hits_headers = true_hits_file.columns  # Extract column names starting from the second column\n",
    "true_hits = pd.DataFrame(true_hits_file.values, columns=true_hits_headers)\n",
    "\n",
    "\n",
    "# plot the waveform of the trap with the highest wvfm in the event\n",
    "for i_evt in range(1):\n",
    "\n",
    "  # mask with the most hits\n",
    "  i_evt_lrs = i_evt\n",
    "\n",
    "  # skip events with no hits\n",
    "  all_traps = summed_wvfms[i_evt_lrs]\n",
    "  all_heights = heights[i_evt_lrs]\n",
    "  all_hits = hits[i_evt_lrs]\n",
    "\n",
    "  # true hits\n",
    "  i_mask = np.argmax(all_hits.sum(axis=1))\n",
    "  i_tpc = i_mask // 2\n",
    "  # Verify column names in the true_hits DataFrame\n",
    "  print(\"Available columns in true_hits:\", true_hits.columns)\n",
    "\n",
    "  # Replace \"event_id\" with the correct column name if it differs\n",
    "  true_hits_list = true_hits[(true_hits[\"event_id\"] == i_evt_lrs) & (true_hits[\"tpc_num\"] == i_tpc)]\n",
    "  events = true_hits_list[\"event_id\"].values\n",
    "  times = true_hits_list[\"start_time_idx\"].values * 16 / 1000\n",
    "\n",
    "  # get wvfm, threshold, and hits for the event\n",
    "  wvfm = summed_wvfms[i_evt_lrs,i_mask]\n",
    "  wvfm_rolled = np.roll(wvfm, n_bins_rolled)\n",
    "  rolling_average = uniform_filter1d(wvfm_rolled, size=n_bins_rolled)\n",
    "  sqrt_rolling_average = np.sqrt(np.abs(rolling_average) * pe_weight**2)\n",
    "  dynamic_threshold = rolling_average + n_sqrt_rt_factor*sqrt_rolling_average\n",
    "  wvfm_gradient = np.gradient(wvfm)\n",
    "  wvfm_grad2 = np.gradient(wvfm_gradient)\n",
    "  wvfm_grad3 = np.gradient(wvfm_grad2)\n",
    "  height = heights[i_evt_lrs,i_mask]\n",
    "  hit = hits[i_evt_lrs,i_mask]\n",
    "  hit_where = np.where(hit)[0]\n",
    "  # verticle line at true hit position\n",
    "  if len(hit_where) == 0:\n",
    "    continue\n",
    "\n",
    "  print(f'Event {i_evt_lrs}, TPC {i_mask // 2}, TrapType {i_mask % 2}')\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "  # Linear plot\n",
    "  ax1.step(time_bins, wvfm)\n",
    "  ax1.axhline(height, color='r', linestyle='--')\n",
    "  ax1.axhspan(0,n_noise_factor*height, color='r', alpha=0.1)\n",
    "  ax1.axhline(0, color='k', linestyle=':')\n",
    "  ax1.step(time_bins, dynamic_threshold, color='g', alpha=0.5)\n",
    "  #ax1.step(time_bins, wvfm_gradient, color='purple', alpha=0.5)\n",
    "  #ax1.step(time_bins, wvfm_grad2, color='pink', alpha=0.5)\n",
    "  #ax1.step(time_bins, wvfm_grad3, color='orange', alpha=0.5)\n",
    "  ax1.step(hit_where * 16/1000, wvfm[hit_where], 'x', color='red', label='Hit')\n",
    "  for t0 in times:\n",
    "    #print(f'True hit at {t0}')\n",
    "    ax1.axvline(t0, color='k', linestyle='--')\n",
    "  #ax1.set_xlim(9, 10)\n",
    "  #ax1.set_ylim(30, 50)\n",
    "  ax1.set_xlabel('Time (us)')\n",
    "  ax1.set_ylabel('SPEs')\n",
    "\n",
    "  # Logarithmic plot\n",
    "  ax2.plot(time_bins, wvfm + 1)\n",
    "  ax2.axhline(height + 1, color='r', linestyle='--')\n",
    "  ax2.axhspan(1,n_noise_factor*height+1, color='r', alpha=0.1)\n",
    "  ax2.axhline(1, color='k', linestyle=':')\n",
    "  #ax2.plot(time_bins, dynamic_threshold + 1, color='g', alpha=0.5)\n",
    "  #ax2.plot(time_bins, wvfm_gradient + 1, color='purple', alpha=0.5)\n",
    "  #ax2.plot(time_bins, wvfm_grad2 + 1, color='pink', alpha=0.5)\n",
    "  #ax2.plot(time_bins, wvfm_grad3 + 1, color='orange', alpha=0.5)\n",
    "  ax2.plot(hit_where * 16/1000, wvfm[hit_where] + 1, 'x', color='red', label='Hit')\n",
    "  for t0 in times:\n",
    "    #print(f'True hit at {t0}')\n",
    "    ax2.axvline(t0, color='k', linestyle='--')\n",
    "  ax2.set_yscale('log')\n",
    "  ax2.set_xlabel('Time (us)')\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting script to plot the summed traptype waveforms per tpc with interactions\n",
    "def plot_summed_trap_waveform_per_tpc_with_interactions(i_evt, time_bins, summed_wvfms, hits, true_hits):\n",
    "\n",
    "  # 2x2 TPC subplot grid, each with traptype sum waveforms\n",
    "  fig, axs = plt.subplots(8, 1, figsize=(15, 15))\n",
    "\n",
    "  for tpc in range(8):\n",
    "    acl_mask = 2*tpc\n",
    "    lcm_mask = 2*tpc + 1\n",
    "\n",
    "    axs[tpc].axhline(0, color='k', linestyle=':')\n",
    "\n",
    "    # get wvfm, threshold, and hits for the event\n",
    "    acl_wvfm = summed_wvfms[i_evt, acl_mask]\n",
    "    acl_hit = hits[i_evt, acl_mask]\n",
    "    acl_hit_where = np.where(acl_hit)[0]\n",
    "\n",
    "    lcm_wvfm = summed_wvfms[i_evt, lcm_mask]\n",
    "    lcm_hit = hits[i_evt, lcm_mask]\n",
    "    lcm_hit_where = np.where(lcm_hit)[0]\n",
    "\n",
    "    # true hits\n",
    "    true_hits_list = true_hits[(true_hits[\"event_id\"] == i_evt) & (true_hits[\"tpc_num\"] == tpc)]\n",
    "    events = true_hits_list[\"event_id\"].values\n",
    "    times = true_hits_list[\"start_time_idx\"].values * 16 / 1000\n",
    "\n",
    "    # plot true hits\n",
    "    for t0 in times:\n",
    "      axs[tpc].axvline(t0, color='k', linestyle='--')\n",
    "\n",
    "    axs[tpc].plot(time_bins, acl_wvfm, label='ACL', color='red', alpha=0.5)\n",
    "    axs[tpc].plot(acl_hit_where * 16/1000, acl_wvfm[acl_hit_where], 'x', color='red', label='Hit')\n",
    "\n",
    "    axs[tpc].plot(time_bins, lcm_wvfm, label='LCM', color='blue', alpha=0.5)\n",
    "    axs[tpc].plot(lcm_hit_where * 16/1000, lcm_wvfm[lcm_hit_where], 'x', color='blue', label='Hit')\n",
    "\n",
    "    axs[tpc].set_xlabel('Time (us)')\n",
    "    axs[tpc].set_ylabel('SPEs')\n",
    "    axs[tpc].set_title(f'TPC {tpc}')\n",
    "\n",
    "    # legend\n",
    "    axs[tpc].legend()\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# load the event number\n",
    "i_evt = 0\n",
    "\n",
    "# load the time bins\n",
    "time_bins = np.linspace(0, 16, 1000)\n",
    "\n",
    "# wvfms\n",
    "summed_wvfms_file = np.load(spes_filenames[0])\n",
    "summed_wvfms = np.array(summed_wvfms_file['arr_0'])\n",
    "\n",
    "# noise thresholds\n",
    "heights_file = np.load(noise_filenames[0])\n",
    "heights = np.array(heights_file['arr_0'])\n",
    "\n",
    "# loading hits\n",
    "hits_file = np.load(hits_filenames[0])\n",
    "hits = np.array(hits_file['arr_0'])\n",
    "\n",
    "# true hits\n",
    "true_hits_file = pd.read_csv(true_hits_filenames[0])\n",
    "# use headers for dataframe\n",
    "true_hits_headers = true_hits_file.columns  # Extract column names starting from the second column\n",
    "true_hits = pd.DataFrame(true_hits_file.values, columns=true_hits_headers)\n",
    "\n",
    "plot_summed_trap_waveform_per_tpc_with_interactions(i_evt, time_bins, summed_wvfms, hits, true_hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 12\n",
    "\n",
    "# info by trap type (ArClight)\n",
    "acl_rec_true_hits_tot = 0\n",
    "acl_true_hits_tot = 0\n",
    "acl_rec_hits_tot = 0\n",
    "acl_delta_t = []\n",
    "# info by trap type (LCM)\n",
    "lcm_rec_true_hits_tot = 0\n",
    "lcm_true_hits_tot = 0\n",
    "lcm_rec_hits_tot = 0\n",
    "lcm_delta_t = []\n",
    "\n",
    "# info by trap type (ArClight) binned by pileup\n",
    "acl_rec_true_hits_pu = []\n",
    "acl_true_hits_pu = []\n",
    "acl_rec_hits_pu = []\n",
    "acl_delta_t_pu = []\n",
    "# info by trap type (LCM) binned by pileup\n",
    "lcm_rec_true_hits_pu = []\n",
    "lcm_true_hits_pu = []\n",
    "lcm_rec_hits_pu = []\n",
    "lcm_delta_t_pu = []\n",
    "\n",
    "# loop over files\n",
    "for i_file in tqdm(range(0, nfiles), desc=\"Processing Files\"):\n",
    "\n",
    "    acl_rec_true_hits = 0\n",
    "    acl_true_hits = 0\n",
    "    acl_rec_hits = 0\n",
    "\n",
    "    lcm_rec_true_hits = 0\n",
    "    lcm_true_hits = 0\n",
    "    lcm_rec_hits = 0\n",
    "\n",
    "    # load true hits\n",
    "    true_hits = pd.read_csv(true_hits_filenames[i_file])\n",
    "    true_hit_idxs = true_hits['start_time_idx'].values\n",
    "\n",
    "    # load ticks histogram of all hits\n",
    "    hits_file = np.load(hits_filenames[i_file])\n",
    "    hits_arr = hits_file['arr_0']\n",
    "    flat_hits = np.sum(hits_arr, axis=(0,1))\n",
    "\n",
    "    # loop over events\n",
    "    for i_evt_lrs in range(hits_arr.shape[0]):\n",
    "\n",
    "        # loop over traps\n",
    "        for i_trap in range(hits_arr.shape[1]):\n",
    "\n",
    "            # indexing for trap type\n",
    "            is_acl = i_trap % 2 == 0\n",
    "            i_tpc = i_trap // 2\n",
    "\n",
    "            # get true hits for this event and trap\n",
    "            true_hit_idxs_tpc = true_hits[(true_hits['event_id'] == i_evt_lrs) & (true_hits['tpc_num'] == i_tpc)]['start_time_idx'].values\n",
    "            hits = np.where(hits_arr[i_evt_lrs, i_trap])[0]\n",
    "\n",
    "            # add rec hits\n",
    "            for i_hit in hits:\n",
    "                if is_acl:\n",
    "                    acl_rec_hits += 1\n",
    "                    acl_rec_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "                else:\n",
    "                    lcm_rec_hits += 1\n",
    "                    lcm_rec_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "            # fill pileup histogram with length-of-true-hits length-of-true-hits times\n",
    "            for true_hit_idx in true_hit_idxs_tpc:\n",
    "\n",
    "                if is_acl:\n",
    "                    # add true hits\n",
    "                    acl_true_hits += 1\n",
    "                    acl_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "                    # get true hit indices within tolerance of this hit\n",
    "                    if hits.size > 0:\n",
    "                        delta_ts = hits - true_hit_idx\n",
    "                        delta_t = delta_ts[(delta_ts < tolerance) & (delta_ts > 0)]\n",
    "                        if delta_t.size > 0:\n",
    "                            acl_delta_t.append(min(delta_t))\n",
    "                            # remove min(delta_t) from the list of available hits to match\n",
    "                            hits = hits[delta_ts != min(delta_t)]\n",
    "                            # add to true rec hits\n",
    "                            acl_rec_true_hits += 1\n",
    "                            acl_rec_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "                else:\n",
    "                    # add true hits\n",
    "                    lcm_true_hits += 1\n",
    "                    lcm_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "                    # get true hit indices within tolerance of this hit\n",
    "                    if hits.size > 0:\n",
    "                        delta_ts = hits - true_hit_idx\n",
    "                        delta_t = delta_ts[(delta_ts < tolerance) & (delta_ts > 0)]\n",
    "                        if delta_t.size > 0:\n",
    "                            lcm_delta_t.append(min(delta_t))\n",
    "                            # remove min(delta_t) from the list of available hits to match\n",
    "                            hits = hits[delta_ts != min(delta_t)]\n",
    "                            # add to true rec hits\n",
    "                            lcm_rec_true_hits += 1\n",
    "                            lcm_rec_true_hits_pu.append(len(true_hit_idxs_tpc))\n",
    "\n",
    "\n",
    "    # caluclate efficiency +/- clopper pearson\n",
    "    '''\n",
    "    print(f'ACL True Hits: {acl_true_hits}')\n",
    "    print(f'ACL Rec Hits: {acl_rec_hits}')\n",
    "    print(f'ACL Rec True Hits: {acl_rec_true_hits}')\n",
    "\n",
    "    print(f'LCM True Hits: {lcm_true_hits}')\n",
    "    print(f'LCM Rec Hits: {lcm_rec_hits}')\n",
    "    print(f'LCM Rec True Hits: {lcm_rec_true_hits}')\n",
    "    '''\n",
    "\n",
    "    # ACL efficiency\n",
    "    acl_eff = acl_rec_true_hits / acl_true_hits\n",
    "    acl_eff_err = clopper_pearson_interval(acl_rec_true_hits, acl_true_hits)\n",
    "    #print(f'ACL Efficiency: {acl_eff:.2f} + {acl_eff_err[1] - acl_eff:.2f} - {acl_eff - acl_eff_err[0]:.2f}')\n",
    "    # ACL fake rate\n",
    "    acl_fake_rate = 1 - (acl_rec_true_hits / acl_rec_hits)\n",
    "    acl_fake_rate_err = clopper_pearson_interval(acl_rec_true_hits, acl_rec_hits)\n",
    "    #print(f'ACL Fake Rate: {acl_fake_rate:.2f} + {1 - acl_fake_rate_err[0] - acl_fake_rate:.2f} - {1 - acl_fake_rate_err[1] - acl_fake_rate:.2f}')\n",
    "\n",
    "    # LCM efficiency\n",
    "    lcm_eff = lcm_rec_true_hits / lcm_true_hits\n",
    "    lcm_eff_err = clopper_pearson_interval(lcm_rec_true_hits, lcm_true_hits)\n",
    "    #print(f'LCM Efficiency: {lcm_eff:.2f} + {lcm_eff_err[1] - lcm_eff:.2f} - {lcm_eff - lcm_eff_err[0]:.2f}')\n",
    "\n",
    "    # LCM fake rate\n",
    "    lcm_fake_rate = 1 - (lcm_rec_true_hits / lcm_rec_hits)\n",
    "    lcm_fake_rate_err = clopper_pearson_interval(lcm_rec_true_hits, lcm_rec_hits)\n",
    "    #print(f'LCM Fake Rate: {lcm_fake_rate:.2f} + {1 - lcm_fake_rate_err[0] - lcm_fake_rate:.2f} - {1 - lcm_fake_rate_err[1] - lcm_fake_rate:.2f}')\n",
    "\n",
    "    # add to totals\n",
    "    acl_rec_true_hits_tot += acl_rec_true_hits\n",
    "    acl_true_hits_tot += acl_true_hits\n",
    "    acl_rec_hits_tot += acl_rec_hits\n",
    "\n",
    "    lcm_rec_true_hits_tot += lcm_rec_true_hits\n",
    "    lcm_true_hits_tot += lcm_true_hits\n",
    "    lcm_rec_hits_tot += lcm_rec_hits\n",
    "\n",
    "\n",
    "# caluclate efficiency +/- clopper pearson\n",
    "print('All files: ')\n",
    "print(f'ACL True Hits: {acl_true_hits_tot}')\n",
    "print(f'ACL Rec Hits: {acl_rec_hits_tot}')\n",
    "print(f'ACL Rec True Hits: {acl_rec_true_hits_tot}')\n",
    "\n",
    "print(f'LCM True Hits: {lcm_true_hits_tot}')\n",
    "print(f'LCM Rec Hits: {lcm_rec_hits_tot}')\n",
    "print(f'LCM Rec True Hits: {lcm_rec_true_hits_tot}')\n",
    "\n",
    "# ACL efficiency\n",
    "acl_eff = acl_rec_true_hits_tot / acl_true_hits_tot\n",
    "acl_eff_err = clopper_pearson_interval(acl_rec_true_hits_tot, acl_true_hits_tot)\n",
    "print(f'ACL Efficiency: {acl_eff:.2f} + {acl_eff_err[1] - acl_eff:.2f} - {acl_eff - acl_eff_err[0]:.2f}')\n",
    "# ACL fake rate\n",
    "acl_fake_rate = 1 - (acl_rec_true_hits_tot / acl_rec_hits_tot)\n",
    "acl_fake_rate_err = clopper_pearson_interval(acl_rec_true_hits_tot, acl_rec_hits_tot)\n",
    "print(f'ACL Fake Rate: {acl_fake_rate:.2f} + {1 - acl_fake_rate_err[0] - acl_fake_rate:.2f} - {1 - acl_fake_rate_err[1] - acl_fake_rate:.2f}')\n",
    "\n",
    "# LCM efficiency\n",
    "lcm_eff = lcm_rec_true_hits_tot / lcm_true_hits_tot\n",
    "lcm_eff_err = clopper_pearson_interval(lcm_rec_true_hits_tot, lcm_true_hits_tot)\n",
    "print(f'LCM Efficiency: {lcm_eff:.2f} + {lcm_eff_err[1] - lcm_eff:.2f} - {lcm_eff - lcm_eff_err[0]:.2f}')\n",
    "\n",
    "# LCM fake rate\n",
    "lcm_fake_rate = 1 - (lcm_rec_true_hits_tot / lcm_rec_hits_tot)\n",
    "lcm_fake_rate_err = clopper_pearson_interval(lcm_rec_true_hits_tot, lcm_rec_hits_tot)\n",
    "print(f'LCM Fake Rate: {lcm_fake_rate:.2f} + {1 - lcm_fake_rate_err[0] - lcm_fake_rate:.2f} - {1 - lcm_fake_rate_err[1] - lcm_fake_rate:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_sided_crystal_ball(x, beta1, m1, beta2, m2, loc, scale, amplitude):\n",
    "    \"\"\"\n",
    "    A smooth Double-Sided Crystal Ball function.\n",
    "\n",
    "    Parameters:\n",
    "    - x: Data points.\n",
    "    - beta1, m1: Left tail parameters (beta1 = tail exponent, m1 = curvature).\n",
    "    - beta2, m2: Right tail parameters.\n",
    "    - loc: Center of the distribution (mean).\n",
    "    - scale: Core width (sigma).\n",
    "    - amplitude: Scaling factor.\n",
    "\n",
    "    Returns:\n",
    "    - Smooth DSCB function values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalized distance from mean\n",
    "    t = (x - loc) / scale\n",
    "\n",
    "    # Transition points\n",
    "    left_cutoff = -beta1\n",
    "    right_cutoff = beta2\n",
    "\n",
    "    y = np.zeros_like(t)\n",
    "\n",
    "    # Left tail (x < loc - beta1 * scale)\n",
    "    left_mask = t < left_cutoff\n",
    "    if np.any(left_mask):\n",
    "        A1 = (m1 / beta1) ** m1 * np.exp(-0.5 * beta1 ** 2)\n",
    "        B1 = m1 / beta1 - beta1\n",
    "        y[left_mask] = A1 * (B1 - t[left_mask]) ** -m1\n",
    "\n",
    "    # Core Gaussian (-beta1 < t < beta2)\n",
    "    core_mask = (t >= left_cutoff) & (t <= right_cutoff)\n",
    "    if np.any(core_mask):\n",
    "        y[core_mask] = np.exp(-0.5 * t[core_mask] ** 2)\n",
    "\n",
    "    # Right tail (x > loc + beta2 * scale)\n",
    "    right_mask = t > right_cutoff\n",
    "    if np.any(right_mask):\n",
    "        A2 = (m2 / beta2) ** m2 * np.exp(-0.5 * beta2 ** 2)\n",
    "        B2 = m2 / beta2 - beta2\n",
    "        y[right_mask] = A2 * (B2 + t[right_mask]) ** -m2\n",
    "\n",
    "    return amplitude * y\n",
    "\n",
    "\n",
    "def plot_histogram_and_fit(ax_main, ax_resid, delta_t, color, label, nbins=10, print_text=False, offset=0.0):\n",
    "    # Histogram\n",
    "    ax_main.hist(delta_t, bins=nbins, range=(0, tolerance), histtype='step', color=color, label=label)\n",
    "\n",
    "    # Bin calculations\n",
    "    hist, bin_edges = np.histogram(delta_t, bins=nbins, range=(0, tolerance))\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    sqrtN = np.sqrt(hist)\n",
    "    ax_main.errorbar(bin_centers, hist, yerr=sqrtN, fmt='none', color=color, alpha=0.5)\n",
    "\n",
    "    # Fit Double-sided Crystal Ball\n",
    "    param_bounds = ([0.1, 0.1, 0.1, 0.1, -np.inf, 1e-6, 1e-6], [10, 10, 10, 10, np.inf, np.inf, np.inf])\n",
    "    p0 = [1.5, 2.0, 1.5, 2.0, np.mean(delta_t), np.std(delta_t), max(hist)]\n",
    "\n",
    "    # loop over parameters and print lower bound < central value < upper bound\n",
    "    for i, p in enumerate(p0):\n",
    "        print(f'Initial guess for parameter {i}: {p} ({param_bounds[0][i]} < {p} < {param_bounds[1][i]})')\n",
    "\n",
    "    popt, _ = curve_fit(double_sided_crystal_ball, bin_centers, hist, p0=p0, bounds=param_bounds, maxfev=10000)\n",
    "    chisq_ndf = np.sum(((hist - double_sided_crystal_ball(bin_centers, *popt)) ** 2) / sqrtN) / (len(hist) - len(p0))\n",
    "\n",
    "    # Plot fit\n",
    "    ax_main.plot(interp_bin_centres, double_sided_crystal_ball(interp_bin_centres, *popt), color=color, linestyle='--', label=f'{label} fit')\n",
    "\n",
    "    # Labels\n",
    "    ax_main.set_ylabel('Counts')\n",
    "    ax_main.legend()\n",
    "\n",
    "    # Residuals\n",
    "    resids = (hist - double_sided_crystal_ball(bin_centers, *popt))\n",
    "    ax_resid.step(bin_centers, resids/sqrtN, color=color)\n",
    "    ax_resid.fill_between(bin_centers, (resids-sqrtN)/sqrtN, (resids+sqrtN)/sqrtN, color=color, alpha=0.5, step='pre')\n",
    "    ax_resid.axhline(0, color='k', linestyle='--')\n",
    "    ax_resid.set_xlabel(r'$\\delta t_0$ (ticks)')\n",
    "    ax_resid.set_ylabel(r'($\\sigma$)')\n",
    "\n",
    "    if print_text:\n",
    "        ax_main.text(\n",
    "            0.05, 0.90-offset, f'$\\mu$ (ns): {popt[4]*16:.2f}',\n",
    "            transform=ax_main.transAxes, color=color, fontsize=11)\n",
    "        ax_main.text(\n",
    "            0.05, 0.80-offset, f'$\\sigma$ (ns):   {popt[5]*16:.2f}',\n",
    "            transform=ax_main.transAxes, color=color, fontsize=11)\n",
    "        ax_main.text(\n",
    "            0.05, 0.65-offset, f'$\\chi^2$/ndf: {chisq_ndf:.2f}',\n",
    "            transform=ax_main.transAxes, color=color, fontsize=11)\n",
    "\n",
    "# Set up figure with GridSpec\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 4), gridspec_kw={'height_ratios': [3, 1]})\n",
    "interp_bin_centres = np.linspace(0, tolerance, 1000)\n",
    "\n",
    "# Plot ACL\n",
    "plot_histogram_and_fit(ax[0, 0], ax[1, 0], acl_delta_t, 'blue', 'ACL', print_text=True)\n",
    "\n",
    "# Plot LCM\n",
    "plot_histogram_and_fit(ax[0, 1], ax[1, 1], lcm_delta_t, 'red', 'LCM', print_text=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure with GridSpec\n",
    "fig, ax = plt.subplots(2, 1, figsize=(5, 5), gridspec_kw={'height_ratios': [3, 1]})\n",
    "interp_bin_centres = np.linspace(0, tolerance, 1000)\n",
    "\n",
    "# Plot ACL\n",
    "plot_histogram_and_fit(ax[0], ax[1], acl_delta_t, 'b', 'ACL', print_text=True)\n",
    "\n",
    "# Plot LCM\n",
    "plot_histogram_and_fit(ax[0], ax[1], lcm_delta_t, 'r', 'LCM', print_text=True, offset=0.5)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize totals for ArClight (ACL) and LCM\n",
    "totals = {\n",
    "    \"acl_rec_true_hits\": 0, \"acl_true_hits\": 0, \"acl_rec_hits\": 0, \"acl_delta_t\": [],\n",
    "    \"lcm_rec_true_hits\": 0, \"lcm_true_hits\": 0, \"lcm_rec_hits\": 0, \"lcm_delta_t\": []\n",
    "}\n",
    "\n",
    "# Binned by pileup\n",
    "totals_pu = {\n",
    "    \"acl_rec_true_hits_pu\": [], \"acl_true_hits_pu\": [], \"acl_rec_hits_pu\": [], \"acl_delta_t_pu\": [],\n",
    "    \"lcm_rec_true_hits_pu\": [], \"lcm_true_hits_pu\": [], \"lcm_rec_hits_pu\": [], \"lcm_delta_t_pu\": []\n",
    "}\n",
    "\n",
    "# Loop over files\n",
    "for i_file in tqdm(range(nfiles), desc=\"Processing Files\"):\n",
    "\n",
    "    # Load true hits and hits array\n",
    "    true_hits = pd.read_csv(true_hits_filenames[i_file])\n",
    "    hits_arr = np.load(hits_filenames[i_file])['arr_0']\n",
    "\n",
    "    # Precompute true hit indices for each event and TPC\n",
    "    grouped_true_hits = true_hits.groupby(['event_id', 'tpc_num'])['start_time_idx'].apply(np.array).to_dict()\n",
    "\n",
    "    # Process hits per event and trap\n",
    "    for i_evt_lrs in range(hits_arr.shape[0]):  # Loop over events\n",
    "        for i_trap in range(hits_arr.shape[1]):  # Loop over traps\n",
    "\n",
    "            # Determine if the trap is ACL or LCM\n",
    "            is_acl = i_trap % 2 == 0\n",
    "            i_tpc = i_trap // 2\n",
    "\n",
    "            # Get true hit indices for this event & TPC\n",
    "            true_hit_idxs_tpc = grouped_true_hits.get((i_evt_lrs, i_tpc), np.array([]))\n",
    "\n",
    "            # Extract nonzero hit indices\n",
    "            hit_indices = np.where(hits_arr[i_evt_lrs, i_trap] > 0)[0]\n",
    "\n",
    "            # Recorded hit counting\n",
    "            for i_hit in hit_indices:\n",
    "                if is_acl:\n",
    "                    totals[\"acl_rec_hits\"] += 1\n",
    "                    totals_pu[\"acl_rec_hits_pu\"].append(len(true_hit_idxs_tpc))\n",
    "                else:\n",
    "                    totals[\"lcm_rec_hits\"] += 1\n",
    "                    totals_pu[\"lcm_rec_hits_pu\"].append(len(true_hit_idxs_tpc))\n",
    "\n",
    "            # Correctly count true hits (restore per-hit counting)\n",
    "            for true_hit_idx in true_hit_idxs_tpc:\n",
    "                if is_acl:\n",
    "                    totals[\"acl_true_hits\"] += 1\n",
    "                    totals_pu[\"acl_true_hits_pu\"].append(len(true_hit_idxs_tpc))\n",
    "                    if hit_indices.size > 0:\n",
    "                        delta_ts = hit_indices - true_hit_idx\n",
    "                        delta_t = delta_ts[(delta_ts < tolerance) & (delta_ts > 0)]\n",
    "                        if delta_t.size > 0:\n",
    "                            totals[\"acl_delta_t\"].append(min(delta_t))\n",
    "                            # remove min(delta_t) from the list of available hits to match\n",
    "                            hit_indices = hit_indices[delta_ts != min(delta_t)]\n",
    "                            totals[\"acl_rec_true_hits\"] += 1\n",
    "                            totals_pu[\"acl_rec_true_hits_pu\"].append(len(true_hit_idxs_tpc))\n",
    "                else:\n",
    "                    totals[\"lcm_true_hits\"] += 1\n",
    "                    totals_pu[\"lcm_true_hits_pu\"].append(len(true_hit_idxs_tpc))\n",
    "                    if hit_indices.size > 0:\n",
    "                        delta_ts = hit_indices - true_hit_idx\n",
    "                        delta_t = delta_ts[(delta_ts < tolerance) & (delta_ts > 0)]\n",
    "                        if delta_t.size > 0:\n",
    "                            totals[\"lcm_delta_t\"].append(min(delta_t))\n",
    "                            # remove min(delta_t) from the list of available hits to match\n",
    "                            hit_indices = hit_indices[delta_ts != min(delta_t)]\n",
    "                            totals[\"lcm_rec_true_hits\"] += 1\n",
    "                            totals_pu[\"lcm_rec_true_hits_pu\"].append(len(true_hit_idxs_tpc))\n",
    "\n",
    "\n",
    "# Compute Efficiency & Fake Rate\n",
    "def compute_metrics(rec_true_hits, true_hits, rec_hits):\n",
    "    eff = rec_true_hits / true_hits if true_hits > 0 else 0\n",
    "    fake_rate = 1 - (rec_true_hits / rec_hits) if rec_hits > 0 else 0\n",
    "    return eff, fake_rate\n",
    "\n",
    "acl_eff, acl_fake_rate = compute_metrics(\n",
    "    totals[\"acl_rec_true_hits\"], totals[\"acl_true_hits\"], totals[\"acl_rec_hits\"]\n",
    ")\n",
    "lcm_eff, lcm_fake_rate = compute_metrics(\n",
    "    totals[\"lcm_rec_true_hits\"], totals[\"lcm_true_hits\"], totals[\"lcm_rec_hits\"]\n",
    ")\n",
    "\n",
    "print(f'ACL Efficiency: {acl_eff:.2f}')\n",
    "print(f'ACL Fake Rate: {acl_fake_rate:.2f}')\n",
    "print(f'LCM Efficiency: {lcm_eff:.2f}')\n",
    "print(f'LCM Fake Rate: {lcm_fake_rate:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ACL distributions\n",
    "acl_pileup_true = totals_pu[\"acl_true_hits_pu\"]\n",
    "acl_pileup_rec = totals_pu[\"acl_rec_hits_pu\"]\n",
    "acl_pileup_rec_true = totals_pu[\"acl_rec_true_hits_pu\"]\n",
    "acl_integral_true = np.sum(acl_pileup_true)\n",
    "acl_integral_rec = np.sum(acl_pileup_rec)\n",
    "acl_integral_rec_true = np.sum(acl_pileup_rec_true)\n",
    "ax[0].hist(acl_pileup_true, bins=12, range=(-2, 10), histtype='step', color='b', label='True Hits, Integral: {:.0f}'.format(acl_integral_true))\n",
    "ax[0].hist(acl_pileup_rec, bins=12, range=(-2, 10), histtype='step', color='g', label='Rec Hits, Integral: {:.0f}'.format(acl_integral_rec))\n",
    "ax[0].hist(acl_pileup_rec_true, bins=12, range=(-2, 10), histtype='step', color='r', label='Rec True Hits, Integral: {:.0f}'.format(acl_integral_rec_true))\n",
    "ax[0].set_xlabel('Pileup')\n",
    "ax[0].set_ylabel('Counts')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('ACL Distributions')\n",
    "\n",
    "# LCM distributions\n",
    "lcm_pileup_true = totals_pu[\"lcm_true_hits_pu\"]\n",
    "lcm_pileup_rec = totals_pu[\"lcm_rec_hits_pu\"]\n",
    "lcm_pileup_rec_true = totals_pu[\"lcm_rec_true_hits_pu\"]\n",
    "lcm_integral_true = np.sum(lcm_pileup_true)\n",
    "lcm_integral_rec = np.sum(lcm_pileup_rec)\n",
    "lcm_integral_rec_true = np.sum(lcm_pileup_rec_true)\n",
    "ax[1].hist(lcm_pileup_true, bins=12, range=(-2, 10), histtype='step', color='b', label='True Hits, Integral: {:.0f}'.format(lcm_integral_true))\n",
    "ax[1].hist(lcm_pileup_rec, bins=12, range=(-2, 10), histtype='step', color='g', label='Rec Hits, Integral: {:.0f}'.format(lcm_integral_rec))\n",
    "ax[1].hist(lcm_pileup_rec_true, bins=12, range=(-2, 10), histtype='step', color='r', label='Rec True Hits, Integral: {:.0f}'.format(lcm_integral_rec_true))\n",
    "ax[1].set_xlabel('Pileup')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('LCM Distributions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorised version of clopper_pearson_interval\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def clopper_pearson_interval_numpy(k, n, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Vectorized Clopper-Pearson confidence interval for binomial proportions.\n",
    "\n",
    "    Parameters:\n",
    "    k : array-like\n",
    "        Number of successes (can be an array).\n",
    "    n : array-like\n",
    "        Number of trials (can be an array).\n",
    "    alpha : float, optional\n",
    "        Significance level, default is 0.05 for a 95% confidence interval.\n",
    "\n",
    "    Returns:\n",
    "    ci_lower : ndarray\n",
    "        Lower bound of the confidence interval.\n",
    "    ci_upper : ndarray\n",
    "        Upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "    k = np.asarray(k, dtype=np.int64)\n",
    "    n = np.asarray(n, dtype=np.int64)\n",
    "\n",
    "    # Ensure valid values\n",
    "    if np.any(k > n):\n",
    "        raise ValueError(\"Number of successes k cannot be greater than number of trials n\")\n",
    "\n",
    "    alpha_2 = alpha / 2\n",
    "\n",
    "    # Compute lower bound\n",
    "    ci_lower = np.where(\n",
    "        k > 0,\n",
    "        st.beta.ppf(alpha_2, k, n - k + 1),\n",
    "        0.0  # If k == 0, lower bound is 0\n",
    "    )\n",
    "    #ci_lower -= k/n\n",
    "\n",
    "    # Compute upper bound\n",
    "    ci_upper = np.where(\n",
    "        k < n,\n",
    "        st.beta.ppf(1 - alpha_2, k + 1, n - k),\n",
    "        1.0  # If k == n, upper bound is 1\n",
    "    )\n",
    "    #ci_upper -= k/n\n",
    "\n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bin edges\n",
    "pu_bins = np.linspace(0, 6, 7)  # Ensure bins cover valid pileup values\n",
    "dt_bins = np.linspace(0, tolerance, tolerance + 1)\n",
    "\n",
    "# ACL histograms\n",
    "acl_delta_t_puhist, _, _ = np.histogram2d(totals_pu[\"acl_rec_true_hits_pu\"], totals[\"acl_delta_t\"], bins=[pu_bins, dt_bins])\n",
    "acl_rec_true_hits_puhist, _ = np.histogram(totals_pu[\"acl_rec_true_hits_pu\"], bins=pu_bins)\n",
    "acl_true_hits_puhist, _ = np.histogram(totals_pu[\"acl_true_hits_pu\"], bins=pu_bins)  # Binwise true hits\n",
    "acl_rec_hits_puhist, _ = np.histogram(totals_pu[\"acl_rec_hits_pu\"], bins=pu_bins)\n",
    "\n",
    "# LCM histograms\n",
    "lcm_delta_t_puhist, _, _ = np.histogram2d(totals_pu[\"lcm_rec_true_hits_pu\"], totals[\"lcm_delta_t\"], bins=[pu_bins, dt_bins])\n",
    "lcm_rec_true_hits_puhist, _ = np.histogram(totals_pu[\"lcm_rec_true_hits_pu\"], bins=pu_bins)\n",
    "lcm_true_hits_puhist, _ = np.histogram(totals_pu[\"lcm_true_hits_pu\"], bins=pu_bins)  # Binwise true hits\n",
    "lcm_rec_hits_puhist, _ = np.histogram(totals_pu[\"lcm_rec_hits_pu\"], bins=pu_bins)\n",
    "\n",
    "# ACL efficiency & error (binwise)\n",
    "acl_eff_pu = acl_rec_true_hits_puhist / acl_true_hits_puhist\n",
    "acl_eff_pu_err = clopper_pearson_interval_numpy(acl_rec_true_hits_puhist, acl_true_hits_puhist)\n",
    "\n",
    "# ACL fake rate & error (binwise)\n",
    "acl_fake_rate_pu = 1 - (acl_rec_true_hits_puhist / acl_rec_hits_puhist)\n",
    "acl_fake_rate_pu_err = clopper_pearson_interval_numpy(acl_rec_true_hits_puhist, acl_rec_hits_puhist)\n",
    "\n",
    "# LCM efficiency & error (binwise)\n",
    "lcm_eff_pu = lcm_rec_true_hits_puhist / lcm_true_hits_puhist\n",
    "lcm_eff_pu_err = clopper_pearson_interval_numpy(lcm_rec_true_hits_puhist, lcm_true_hits_puhist)\n",
    "\n",
    "# LCM fake rate & error (binwise)\n",
    "lcm_fake_rate_pu = 1 - (lcm_rec_true_hits_puhist / lcm_rec_hits_puhist)\n",
    "lcm_fake_rate_pu_err = clopper_pearson_interval_numpy(lcm_rec_true_hits_puhist, lcm_rec_hits_puhist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot efficiency and fake rate as a function of pileup\n",
    "fig, ax = plt.subplots(2, figsize=(8, 5))\n",
    "\n",
    "# plot acl efficiency\n",
    "ax[0].step(pu_bins[:-1], acl_eff_pu, label='ACL')\n",
    "ax[0].fill_between(pu_bins[:-1], acl_eff_pu_err[0], acl_eff_pu_err[1], step='pre', alpha=0.2)\n",
    "# plot lcm efficiency\n",
    "ax[0].step(pu_bins[:-1], lcm_eff_pu, label='LCM')\n",
    "ax[0].fill_between(pu_bins[:-1], lcm_eff_pu_err[0], lcm_eff_pu_err[1], step='pre', alpha=0.2)\n",
    "# formatting\n",
    "ax[0].set_ylabel('Efficiency')\n",
    "ax[0].set_xlabel('Pileup')\n",
    "ax[0].set_xlim(0, 5)\n",
    "ax[0].set_ylim(0, 1)\n",
    "ax[0].legend()\n",
    "\n",
    "# plot acl fake rate\n",
    "ax[1].step(pu_bins[:-1], acl_fake_rate_pu, label='ACL')\n",
    "ax[1].fill_between(pu_bins[:-1], 1-acl_fake_rate_pu_err[0], 1-acl_fake_rate_pu_err[1], step='pre', alpha=0.2)\n",
    "# plot lcm fake rate\n",
    "ax[1].step(pu_bins[:-1], lcm_fake_rate_pu, label='LCM')\n",
    "ax[1].fill_between(pu_bins[:-1], 1-lcm_fake_rate_pu_err[0], 1-lcm_fake_rate_pu_err[1], step='pre', alpha=0.2)\n",
    "# formatting\n",
    "ax[1].set_ylabel('Fake Rate')\n",
    "ax[1].set_xlabel('Pileup')\n",
    "ax[1].set_xlim(0, 5)\n",
    "ax[1].set_ylim(0, 1)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Plot ACL and LCM efficiency (top left)\n",
    "ax[0, 0].step(pu_bins[:-1], acl_eff_pu, label='ACL')\n",
    "ax[0, 0].fill_between(pu_bins[:-1], acl_eff_pu_err[0], acl_eff_pu_err[1], step='pre', alpha=0.2)\n",
    "ax[0, 0].step(pu_bins[:-1], lcm_eff_pu, label='LCM')\n",
    "ax[0, 0].fill_between(pu_bins[:-1], lcm_eff_pu_err[0], lcm_eff_pu_err[1], step='pre', alpha=0.2)\n",
    "ax[0, 0].set_ylabel('Efficiency')\n",
    "ax[0, 0].set_xlim(0, 7)\n",
    "ax[0, 0].set_ylim(0, 1)\n",
    "ax[0, 0].legend()\n",
    "\n",
    "# Plot ACL and LCM fake rate (top right)\n",
    "ax[0, 1].step(pu_bins[:-1], acl_fake_rate_pu, label='ACL')\n",
    "ax[0, 1].fill_between(pu_bins[:-1], 1 - acl_fake_rate_pu_err[0], 1 - acl_fake_rate_pu_err[1], step='pre', alpha=0.2)\n",
    "ax[0, 1].step(pu_bins[:-1], lcm_fake_rate_pu, label='LCM')\n",
    "ax[0, 1].fill_between(pu_bins[:-1], 1 - lcm_fake_rate_pu_err[0], 1 - lcm_fake_rate_pu_err[1], step='pre', alpha=0.2)\n",
    "ax[0, 1].set_ylabel('Fake Rate')\n",
    "ax[0, 1].set_xlim(0, 7)\n",
    "ax[0, 1].set_ylim(0, 1)\n",
    "ax[0, 1].legend()\n",
    "\n",
    "# Plot efficiency ratio (bottom left)\n",
    "ratio_eff = lcm_eff_pu / acl_eff_pu\n",
    "acl_eff_err_scaled = acl_eff_pu_err / acl_eff_pu\n",
    "lcm_eff_err_scaled = lcm_eff_pu_err / acl_eff_pu\n",
    "\n",
    "ax[1, 0].step(pu_bins[:-1], [1] * len(pu_bins[:-1]), label='ACL')\n",
    "ax[1, 0].fill_between(pu_bins[:-1], acl_eff_err_scaled[0], acl_eff_err_scaled[1], step='pre', alpha=0.2)\n",
    "ax[1, 0].step(pu_bins[:-1], ratio_eff, label='LCM')\n",
    "ax[1, 0].fill_between(pu_bins[:-1], lcm_eff_err_scaled[0], lcm_eff_err_scaled[1], step='pre', alpha=0.2)\n",
    "ax[1, 0].set_ylabel('1 / ACL')\n",
    "ax[1, 0].set_xlabel('Pileup')\n",
    "ax[1, 0].set_xlim(0, 7)\n",
    "ax[1, 0].set_ylim(0.5, 1.5)\n",
    "\n",
    "# Plot fake rate ratio (bottom right)\n",
    "ratio_fake = lcm_fake_rate_pu / acl_fake_rate_pu\n",
    "acl_fake_err_scaled = (1 - np.array(acl_fake_rate_pu_err)) / acl_fake_rate_pu\n",
    "lcm_fake_err_scaled = (1 - np.array(lcm_fake_rate_pu_err)) / acl_fake_rate_pu\n",
    "\n",
    "ax[1, 1].step(pu_bins[:-1], [1] * len(pu_bins[:-1]), label='ACL')\n",
    "ax[1, 1].fill_between(pu_bins[:-1],  acl_fake_err_scaled[0], acl_fake_err_scaled[1], step='pre', alpha=0.2)\n",
    "ax[1, 1].step(pu_bins[:-1], ratio_fake, label='LCM')\n",
    "ax[1, 1].fill_between(pu_bins[:-1], lcm_fake_err_scaled[0], lcm_fake_err_scaled[1], step='pre', alpha=0.2)\n",
    "ax[1, 1].set_ylabel('1 / ACL')\n",
    "ax[1, 1].set_xlabel('Pileup')\n",
    "ax[1, 1].set_xlim(0, 7)\n",
    "ax[1, 1].set_ylim(0.5, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plot the pileup vs delta t space for each trap type\n",
    "pu_bins = np.linspace(0, 8, 9)  # Ensure bins cover valid pileup values\n",
    "\n",
    "# 2d heatmap\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# ACL\n",
    "hist_acl_data, xedges_acl, yedges_acl, _ = ax[0].hist2d(np.array(totals_pu[\"acl_rec_true_hits_pu\"])-1, totals[\"acl_delta_t\"], bins=[pu_bins, dt_bins], cmap='Blues')\n",
    "\n",
    "\n",
    "ax[0].set_xlabel('Pileup')\n",
    "ax[0].set_ylabel('Delta T (ticks)')\n",
    "ax[0].set_title('ACL Delta T vs Pileup')\n",
    "# LCM\n",
    "hist_lcm_data, xedges_lcm, yedges_lcm, _ = ax[1].hist2d(np.array(totals_pu[\"lcm_rec_true_hits_pu\"])-1, totals[\"lcm_delta_t\"], bins=[pu_bins, dt_bins], cmap='Reds')\n",
    "\n",
    "\n",
    "ax[1].set_ylabel('Delta T (ticks)')\n",
    "ax[1].set_title('LCM Delta T vs Pileup')\n",
    "# add colorbars\n",
    "fig.colorbar(ax[0].collections[0], ax=ax[0], label='Counts')\n",
    "fig.colorbar(ax[1].collections[0], ax=ax[1], label='Counts')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# then run a double crystal ball fit per trap type in each pilep bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take hist_acl_data and make it cumulative in the y-axis and plot\n",
    "\n",
    "acl_cum_hist = np.cumsum(hist_acl_data, axis=0)\n",
    "\n",
    "lcm_cum_hist = np.cumsum(hist_lcm_data, axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndlar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
